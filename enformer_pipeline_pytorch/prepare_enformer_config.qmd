---
title: "This qmd file helps to prepare configuration files for enformer"
author: "Temi and Sai"
date: 'Thurs Feb 23 2023'
format: 
  pdf: 
    toc: true
    number-sections: true
    code-line-numbers: true
---

```{r}
library(glue)
library(rjson)
library(data.table)
library(GenomicRanges)
library(parallel)
library(tidyverse)
library(jsonlite)
```
```{r}
imlab_dir <- '/lus/grand/projects/covid-ct/imlab'
data_dir <- glue('{imlab_dir}/data/freedman_data/peaks_liftover')
project_dir <- glue('{imlab_dir}/users/shared/enformer_pipeline')
metadata_dir <- glue('{project_dir}/metadata')
```

```{r}
dataset <- 'saideepDataset'
prediction_id <- 'HRR'
todays_date <- data_date <- run_date <- Sys.Date()
```

### Prepare vcf files for the config
```{r}
valid_chromosomes <- c(paste('chr', 1:22, sep=''), "chrX")
valid_chromosomes
```

```{r}
pat <- paste0('*.', valid_chromosomes, '.*vcf.gz$', collapse='|') # paste0('^', TF_info$DCid, collapse='_*|')
vcfs_dir <- glue('{imlab_dir}/data/GEUVADIS/vcf_snps_only')
grep(pattern=glue('{pat}'), list.files(vcfs_dir), value=TRUE)
```

```{r}
vcf_files <- lapply(valid_chromosomes, function(chr){
    pat <- paste0('*.\\b', chr, '\\b.*vcf.gz$', collapse='|')
    #print(pat)
    grep(pattern=glue('{pat}'), list.files(vcfs_dir), value=TRUE)
})
names(vcf_files) <- valid_chromosomes
vcf_files
```

```{r}
vcf_files <- list(folder=glue('{imlab_dir}/data/GEUVADIS/vcf_snps_only'), files=vcf_files)
vcf_files
```

```{r}
list.files(vcfs_dir, pattern=glue('*.{pat}.*vcf.gz'))
```

### Prepare prediction file
```{r}
predictor_file <- glue('{metadata_dir}/protein_coding_nosex.bed')
if(!file.exists(predictor_file)){
    print('predictor_file does not exist')
} 
predictor_dt <- data.table::fread(predictor_file)
predictor_dt %>% tidyr::unite('X', V1:V3) %>% pull(X) %>% write.table(glue('{metadata_dir}/genes_predictor_files.txt'), row.names=F, col.names=F)
```
```{r}
configuration_dir <- glue('{project_dir}/config_files')
if(!dir.exists(configuration_dir)){
    dir.create(configuration_dir, recursive=T)
} else {
    print('Configuration folder exists')
}
```

```{r}
# check that your individuals are present in the vcf
individuals_file <- data.table::fread(glue('{metadata_dir}/all_inds.txt'), header=F)$V1
#individuals_geuvadis <- data.table::fread(glue('{project_dir}/metadata/{dataset}_individuals.txt'), header=F)$V1
#individuals_99 <- data.table::fread(glue('{project_dir}/metadata/99_individuals.txt'), header=F)$V1
```

```{r}
#valid_individuals <- individuals_99[individuals_99 %in% individuals_1kg]
write.table(individuals_file, file=glue('{metadata_dir}/predict_on_individuals.txt'), quote=F, row.names=F, col.names=F)
```


```{r}
enformer_parameters_json <- list()

# '/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/TFpred_pipeline/metadata/individuals.txt'
enformer_parameters_json[['individuals']] <- glue('{metadata_dir}/predict_on_individuals.txt')
enformer_parameters_json[['n_individuals']] <- 60
enformer_parameters_json[['project_dir']] <- as.character(project_dir)
enformer_parameters_json[['interval_list_file']] <- glue('{metadata_dir}/genes_predictor_files.txt')
enformer_parameters_json[['prediction_data_name']] <- dataset
enformer_parameters_json[['prediction_id']] <- prediction_id
enformer_parameters_json[['date']] <- data_date
enformer_parameters_json[['create_hdf5_file']] <- FALSE
enformer_parameters_json[['exclude_regions']] <- TRUE
enformer_parameters_json[['batch_individuals']] <- 20
enformer_parameters_json[['vcf_split']] <- TRUE
enformer_parameters_json[['vcf_files']] <- vcf_files

#enformer_parameters_json[['vcf_file']] <- "/lus/grand/projects/covid-ct/imlab/users/temi/projects/TFXcan/genotypes/prj6_genotypes/merged_phased_SNPs.vcf.gz"

enformer_parameters_json[['sub_dir']] <- TRUE
enformer_parameters_json[['use_parsl']] <- TRUE
enformer_parameters_json[['model_path']] <- "/lus/grand/projects/covid-ct/imlab/data/enformer/raw"
enformer_parameters_json[['hg38_fasta_file']] <- "/lus/grand/projects/covid-ct/imlab/data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta"
enformer_parameters_json[['metadata_dir']] <- glue('{project_dir}/metadata')
enformer_parameters_json[['output_dir']] <- "enformer_predictions"
enformer_parameters_json[['sequence_source']] <- "personalized"
enformer_parameters_json[['predictions_log_dir']] <- "predictions_log"
enformer_parameters_json[['batch_regions']] <- 10
enformer_parameters_json[['n_regions']] <- 100
enformer_parameters_json[['write_log']] <- list('logdir' = glue('job_logs'), 'logtypes' = list('memory'=T, 'error'=T, 'time'=F, 'cache'=T))
enformer_parameters_json[['parsl_parameters']] <- list("job_name"=glue("enformer_predict_{dataset}_{prediction_id}"), "num_of_full_nodes"=1, "walltime"="06:00:00", "min_num_blocks"=0, "max_num_blocks"=8, "queue"="full-node", 'hpc'='theta', "provider"="local") 

write(
    jsonlite::toJSON(enformer_parameters_json, na='null', pretty=TRUE, auto_unbox=T),
    file=glue('{configuration_dir}/enformer_parameters_{dataset}_{prediction_id}.json')
)

# 
param_file <- glue('{configuration_dir}/enformer_parameters_{dataset}_{prediction_id}.json')
param_file
```


```{r}
prediction_cmd <- glue('screen\nconda activate dl-tools\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/temi/miniconda3/envs/dl-tools/lib\npython3 {project_dir}/parallel_enformer/enformer_predict.py --param_config {param_file}')
prediction_cmd
```