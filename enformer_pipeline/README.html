<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>readme</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="README_files/libs/clipboard/clipboard.min.js"></script>
<script src="README_files/libs/quarto-html/quarto.js"></script>
<script src="README_files/libs/quarto-html/popper.min.js"></script>
<script src="README_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="README_files/libs/quarto-html/anchor.min.js"></script>
<link href="README_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="README_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="README_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="README_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="README_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="shared-enformer-repo" class="level1">
<h1>Shared ENFORMER repo</h1>
<p>Pipeline used to run ENFORMER</p>
<section id="authors-sai-and-temi" class="level3">
<h3 class="anchored" data-anchor-id="authors-sai-and-temi">Authors: Sai and Temi</h3>
</section>
<section id="date-sometime-in-february-2023" class="level3">
<h3 class="anchored" data-anchor-id="date-sometime-in-february-2023">Date: Sometime in February 2023</h3>
</section>
<section id="usage" class="level2">
<h2 class="anchored" data-anchor-id="usage">Usage</h2>
<section id="clone-the-repo" class="level3">
<h3 class="anchored" data-anchor-id="clone-the-repo">1. Clone the repo</h3>
<p>clone the repo using: <code>git clone https://github.com/hakyimlab/shared_folder.git</code>.</p>
</section>
<section id="install-the-software" class="level3">
<h3 class="anchored" data-anchor-id="install-the-software">2. Install the software</h3>
<ul>
<li>If you don’t have conda installed, please install conda. <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/">Install conda</a></li>
</ul>
</section>
<section id="create-conda-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-conda-environment">3. Create conda environment</h3>
<ul>
<li><p>If you are on polaris, you can use the shared software environment: <code>/lus/grand/projects/TFXcan/imlab/shared/software/conda_envs/enformer-predict-tools</code></p></li>
<li><p>If you are not on polaris, you can create your own environment using the <a href="./software/enformer-predict-tools.yaml"><code>enformer-predict-tools.yaml</code></a> file.</p>
<p><code>conda env create -p &lt;path to where you want to put the environment&gt; (e.g. ./enformer-predict-tools) -f [](./software/enformer_pipeline/software/enformer-predict-tools.yaml)</code></p></li>
</ul>
<p>This environment contains all the software needed to run the pipeline; and you should remember to use it in the configuration file defined below.</p>
</section>
<section id="activate-conda-environment" class="level3">
<h3 class="anchored" data-anchor-id="activate-conda-environment">4. Activate conda environment</h3>
<p><code>conda activate &lt;&lt;path to the environment&gt;&gt; (e.g. ./enformer-predict-tools)</code></p>
</section>
<section id="edit-the-config.json-file" class="level3">
<h3 class="anchored" data-anchor-id="edit-the-config.json-file">5. Edit the config.json file</h3>
<p>Instructions are below.</p>
</section>
<section id="run-the-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="run-the-pipeline">6. Run the pipeline</h3>
<p>There are two ways to do this:</p>
<ol type="1">
<li><p>After editing your <code>config.json</code> file , simply call: <a href="./scripts/enformer_predict.py"><code>python3 ./scripts/enformer_predict.py</code></a> –param_config <code>{path to config.json file}</code>. <strong>Make sure that the <code>provider</code> option is set to ’highthroughput” in the config file.</strong></p></li>
<li><p>Edit the <a href="./scripts/enformer_predict.sh"><code>enformer_predict.sh</code></a> file to include the path to your config.json file and then call: <a href="./scripts/enformer_predict.sh"><code>qsub ./enformer_predict.sh</code></a>. <strong>Make sure that the <code>provider</code> option is set to ’local” in the config file.</strong></p></li>
</ol>
<section id="difference-between-highthroughput-and-local-providers" class="level4">
<h4 class="anchored" data-anchor-id="difference-between-highthroughput-and-local-providers">Difference between “highthroughput” and “local” providers</h4>
<p>The “highthroughput” provider is used when you want to run the pipeline on a cluster from the login nodes. To make sure your job does not stop when logged out, you can use screen or tmux. The “local” provider is used when you want to run the pipeline as if on your local machine. Here, you have direct access to some gpus, or have requested an interactive session. So, when submitting a pbs script or job, you need to use the “local” provider.</p>
<p>An example of a config.json file is <a href="./config_files">here</a>. You should choose one depending on if you want to predict on the reference genome or on personalized genomes, and on what cluster you are on. Instructions for the config.json file are below. Template files for individuals and regions are <a href="./metadata/">here</a>.</p>
</section>
</section>
</section>
<section id="options" class="level2">
<h2 class="anchored" data-anchor-id="options">Options</h2>
<section id="general-and-fatal-if-not-provided" class="level3">
<h3 class="anchored" data-anchor-id="general-and-fatal-if-not-provided">General (and fatal if not provided)</h3>
<ul>
<li><code>project_dir</code>: (relative or absolute path) Provide a directory where files, logs, and outputs will be created.</li>
<li><code>sub_dir</code>: (Bool: true or false) To make the folders clean, predictions will be saved in <code>{project_dir}/predictions_folder/</code></li>
<li><code>model_path</code>: (relative or absolute path) Path to ENFORMER model.</li>
<li><code>fasta_file</code>: (Absolute path) Path to the fasta file containing the reference sequences.</li>
<li><code>interval_list_file</code>: (Relative path to this tab-delimited file) Path to the file where the intervals files are saved.</li>
<li><code>output_dir</code>: (str) name of the folder where predictions will be saved i.e <code>{project_dir}/predictions_folder/{prediction_data_name}_{prediction_id}/predictions_{date}/{output_dir}</code></li>
<li><code>sequence_source</code>: (str: “reference” or “personalized”, “random”) A name for the type of dataset. This is necessary so that the pipeline knows whether to use vcf files or not.</li>
<li><code>reverse_complement</code>: (bool) Do you want to make predictions for the reverse complement of the extracted sequence too. Currently, this only works when doing personalized predictions. THIS DOES NOT WORK FOR REFERENCE OR RANDOM ONLY PREDICTIONS YET.</li>
<li><code>prediction_data_name</code>: (str) A unique id for the predictions that will be used to create folders. Can also use the name of the dataset e.g.&nbsp;“freedman”, or “kawakami”. If <code>dataset_type</code> is “reference”, this will be the name of the folder within which predictions will be made. If <code>dataset_type</code> is personalized, the unique ids of the individuals will be used.</li>
<li><code>prediction_id</code>: (str) A unique id</li>
<li><code>predictions_log_dir</code>: (path to folder): Where should predictions be logged? In the event of the job not completing and you intend to re-run, the file <code>{project_dir}/predictions_folder/{prediction_data_name}_{prediction_id}/predictions_{date}/{predictions_log_dir}/{individual or id}_log.csv</code> will be read and used such that if a prediction for a region exists and the <code>{region}_predictions.h5</code> file exists, predictions will not be made for that region anylonger.</li>
<li><code>batch_regions</code>: (int) Predictions for intervals or regions will be split into <code>batch_regions</code>.<br>
</li>
<li><code>n_regions</code>: (int) how many regions should be predicted for at a time. If using parsl, each gpu/parsl app will get at most <code>n_regions</code> at a time.</li>
<li><code>tracks_to_save</code>: indices of ENFORMER tracks to be saved; -1 for all.</li>
<li><code>bins_to_save</code>: indices of ENFORMER bins to be saved; -1 for all</li>
</ul>
</section>
<section id="personalized-predictions-optional-used-only-when-predicting-on-individuals" class="level3">
<h3 class="anchored" data-anchor-id="personalized-predictions-optional-used-only-when-predicting-on-individuals">Personalized predictions (optional; used only when predicting on individuals)</h3>
<ul>
<li><code>individuals</code>:(path, list or str) The unique ids of the individuals whose predictions are to be made. If providing a file, the ids should be written row-wise. A list of ids can be supplied and a single id can be supplied as a string.</li>
<li><code>n_individuals</code>: (int) how many individuals to predict on; -1 for all.</li>
<li><code>batch_individuals</code>: (int) how many individuals to predict on at a time; -1 for all. Individuals will be split into <code>batch_individuals</code>.</li>
<li><code>vcf_files</code>: (path) A nested json of the path to the phased vcf file that contains the genotypes/variants of the individuals.
<ul>
<li><code>folder</code>: (path) the directory where the vcf files are located</li>
<li><code>files</code>: a nested json of <code>{chr_n: vcf_file_n}</code></li>
</ul></li>
</ul>
</section>
<section id="optional" class="level3">
<h3 class="anchored" data-anchor-id="optional">Optional</h3>
<ul>
<li><code>exclude_regions</code>: (path to file or null): During predictions if there are issues with some regions, those regions are logged here, and will be excluded if the job is re-run.</li>
<li><code>date</code>: (str in the form “YYYY-MM-DD”) The date these predictions are made. If not supplied, today’s date will be used.</li>
<li><code>use_parsl</code>: (bool: true or false) Should parsl be used to make predicting run faster? If <code>false</code> only one GPU is used.</li>
<li><code>write_log</code>: (dict of bools) A nested json directive
<ul>
<li><code>logdir</code>: (str) name of the log directory</li>
<li><code>logtypes</code>: Controls what logs should be written. Any of <code>memory</code>, <code>cache</code>, <code>error</code> or <code>time</code>, and possible values are <code>true</code> or <code>false</code>.</li>
</ul></li>
<li><code>parsl_parameters</code>: (dict of bools) If <code>use_parsl</code> is true, these parameters are passed to parsl. Dictionary keys are <code>job_name</code>, <code>num_of_full_nodes</code>, <code>walltime</code>, <code>min_num_blocks</code>, <code>queue</code>, and <code>max_num_blocks</code>
<ul>
<li><code>job_name</code>: (str) e.g.&nbsp;“my_predictions”</li>
<li><code>num_of_full_nodes</code>: (int) e.g.&nbsp;10</li>
<li><code>walltime</code>: (str) “HH:MM:SS” e.g.&nbsp;“01:10:59”</li>
<li><code>init_blocks</code>: (int) e.g.&nbsp;1</li>
<li><code>min_num_blocks</code>: (int) e.g.&nbsp;0</li>
<li><code>max_num_blocks</code>: (int) e.g.&nbsp;1</li>
<li><code>queue</code>: (str) e.g.&nbsp;“preemptable”, “full-node”</li>
<li><code>account</code>: (str) e.g.&nbsp;“haky”, “pi-haky”, “TFXcan”, “covid-ct”</li>
<li><code>hpc</code>: (str) e.g.&nbsp;“beagle3”, “polaris”, “theta”</li>
<li><code>provider</code>: (str) e.g.&nbsp;“highthroughput”, “local”</li>
<li><code>worker_init</code>: (str) e.g.&nbsp;“conda activate ./enformer-predict-tools; which python; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:./enformer-predict-tools/lib”</li>
</ul></li>
</ul>
</section>
</section>
<section id="to-do" class="level2">
<h2 class="anchored" data-anchor-id="to-do">To-do</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="">&gt; :heavy_exclamation_mark: Allow the submission of a bash script to the queue.</li>
<li><input type="checkbox" disabled="" checked="">Check that <code>os.path.join</code> paths work correctly.</li>
<li><input type="checkbox" disabled="" checked="">User should supply the intervals list within the predictions folder.</li>
<li><input type="checkbox" disabled="">Provide a module to ensure that inputs are appropriate and available</li>
<li><input type="checkbox" disabled="">&gt; :heavy_exclamation_mark: Provide checks to ensure that necessary files and folders are available.</li>
<li><input type="checkbox" disabled="" checked="">Change <code>hg38_fasta_file</code> to a better, more general name like <code>fasta_file</code></li>
<li><input type="checkbox" disabled="" checked="">Ensure that the pipeline works with relative paths.</li>
<li><input type="checkbox" disabled="" checked="">Change “motif” to “region” in the predictions_log files names</li>
<li><input type="checkbox" disabled="" checked="">Pipeline should be able to predict on reverse complements</li>
<li><input type="checkbox" disabled="" checked="">Create config templates for different servers (beagle3, polaris, theta e.t.c.)</li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>